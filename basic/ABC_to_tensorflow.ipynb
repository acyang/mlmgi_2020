{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 的基本運算單位是張量（Tensor），零維張量等於是純量(Scalar)，一維張量是向量(Vector)，二維張量是矩陣(Matrix)等等。和Numpy相對比，ndarray（n 維陣列）觀念與 Tensor（n 維張量）觀念類似以外，TensorFlow 函數的命名、參數與設計概念都很接近 NumPy。\n",
    "\n",
    "複習一下Tensorflow主要的運作流程分為以下兩個部分\n",
    "* 建立模型(Build Model)\n",
    "* 執行運算(Run)\n",
    "\n",
    "Tensorflow設計的核心就是Tensor的流動，建立Graph的過程其實只是定義好Tensor如何流動並運算的過程，但真正的資料其實並沒有被運算，真正的計算需要用session來執行。\n",
    "![graph](https://www.tensorflow.org/images/tensors_flowing.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "one_d_arr = np.arange(24)\n",
    "two_d_arr = np.arange(24).reshape(6, 4)\n",
    "three_d_arr = np.arange(24).reshape(2, 3, 4)\n",
    "\n",
    "print(\"Python:\")\n",
    "print(one_d_arr.ndim)\n",
    "print(two_d_arr.ndim)\n",
    "print(three_d_arr.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "one_d_tensor = tf.constant(np.arange(24))\n",
    "two_d_tensor = tf.constant(np.arange(24), shape=(6, 4))\n",
    "three_d_tensor = tf.constant(np.arange(24), shape=(2, 3, 4))\n",
    "\n",
    "print(\"TensorFlow:\")\n",
    "print(len(one_d_tensor.get_shape()))\n",
    "print(len(two_d_tensor.get_shape()))\n",
    "print(len(three_d_tensor.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World'\n"
     ]
    }
   ],
   "source": [
    "hw = tf.constant(\"Hello World\")\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(hw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 3.]\n",
      " [3. 7.]]\n"
     ]
    }
   ],
   "source": [
    "# Build a dataflow graph.\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "e = tf.matmul(c, d)\n",
    "\n",
    "# Construct a `Session` to execute the graph.\n",
    "with tf.Session() as sess:\n",
    "  # Execute the graph and store the value that `e` represents in `result`.\n",
    "  result = sess.run(e)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor可以被宣告為常數（Constant）、變數（Variable）或者 佔位符(Placeholder) 這三種類型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 常數（Constant）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:\n",
      "22\n",
      "16\n",
      "57\n",
      "6.333333333333333\n",
      "6859\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#In Python, constants are written in all capital letters\n",
    "print(\"Python:\")\n",
    "A = 19\n",
    "B = 3\n",
    "print(A + B)\n",
    "print(A - B)\n",
    "print(A * B)\n",
    "print(A / B)\n",
    "print(A** B)\n",
    "print(A % B)\n",
    "print(A// B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor數值運算這些函數都必須在 TensorFlow 的 Session 中執行才會有運算結果的輸出，否則只是顯示張量物件的資訊而已。\n",
    "\n",
    "* 加 +：tf.add()\n",
    "* 減 -： tf.sub()\n",
    "* 乘 *： tf.multiply()\n",
    "* 除 /： tf.divide()\n",
    "* 次方 **： tf.pow()\n",
    "* 求餘數 %： tf.mod()\n",
    "* 求商數 //：tf.div()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\n",
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Sub:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n",
      "Tensor(\"truediv:0\", shape=(), dtype=float64)\n",
      "Tensor(\"Pow:0\", shape=(), dtype=int32)\n",
      "Tensor(\"FloorMod:0\", shape=(), dtype=int32)\n",
      "Tensor(\"div:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(19)\n",
    "y = tf.constant(3)\n",
    "\n",
    "print(\"TensorFlow:\")\n",
    "print( tf.add(x, y) )\n",
    "print( tf.subtract(x, y) )\n",
    "print( tf.multiply(x, y) )\n",
    "print( tf.divide(x, y) )\n",
    "print( tf.pow(x, y) )\n",
    "print( tf.mod(x, y) )\n",
    "print( tf.div(x, y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一個 Tensor的運算需要三個步驟：\n",
    "\n",
    "1. 宣告張量\n",
    "2. 使用張量的運算公式\n",
    "3. 在 Session 裡執行運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "16\n",
      "57\n",
      "6.333333333333333\n",
      "6859\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print( sess.run(tf.add(x, y)) )\n",
    "    print( sess.run(tf.subtract(x, y)) )\n",
    "    print( sess.run(tf.multiply(x, y)) )\n",
    "    print( sess.run(tf.divide(x, y)) )\n",
    "    print( sess.run(tf.pow(x, y)) )\n",
    "    print( sess.run(tf.mod(x, y)) )\n",
    "    print( sess.run(tf.div(x, y)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "16\n",
      "57\n",
      "6.333333333333333\n",
      "6859\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#使用運算符號也可以，但也是要記得在 Session 中執行。\n",
    "with tf.Session() as sess:\n",
    "    print( sess.run(x + y) )\n",
    "    print( sess.run(x - y) )\n",
    "    print( sess.run(x * y) )\n",
    "    print( sess.run(x / y) )\n",
    "    print( sess.run(x**y) )\n",
    "    print( sess.run(x % y) )\n",
    "    print( sess.run(x // y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Session:\n",
      "22\n",
      "16\n",
      "57\n",
      "6.333333333333333\n",
      "6859\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "isess = tf.InteractiveSession()\n",
    "\n",
    "print(\"Interactive Session:\")\n",
    "print( tf.add(x, y).eval() )\n",
    "print( tf.subtract(x, y).eval() )\n",
    "print( tf.multiply(x, y).eval() )\n",
    "print( tf.divide(x, y).eval() )\n",
    "print( tf.pow(x, y).eval() )\n",
    "print( tf.mod(x, y).eval() )\n",
    "print( tf.div(x, y).eval() )\n",
    "\n",
    "isess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用的常數張量建構函數有:\n",
    "* tf.zeros() ：建構內容數值皆為 0 的常數向量\n",
    "* tf.ones() ：建構內容數值皆為 1 的常數向量\n",
    "* tf.fill() ：建構內容數值皆為特定值的常數向量\n",
    "* tf.range() ：建構內容數值為 (start, limit, delta) 數列的常數向量\n",
    "* tf.random_normal() ：建構內容數值為符合常態分佈數列的常數向量\n",
    "* tf.random_uniform() ：建構內容數值為符合均勻分佈數列的常數向量\n",
    "\n",
    "常用的矩陣運算函數有:\n",
    "* tf.reshape() ：調整矩陣外觀\n",
    "* tf.eye() ：建構單位矩陣\n",
    "* tf.diag() ：建構對角矩陣\n",
    "* tf.matrix_transpose() ：轉置矩陣\n",
    "* tf.matmul() ：矩陣相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy:\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[5 5]\n",
      " [5 5]]\n",
      "[[1 3]\n",
      " [5 7]]\n",
      "[[-0.707008   -0.52875076]\n",
      " [ 0.44092994  1.92858202]]\n",
      "[[0.35095293 0.53890325]\n",
      " [0.06470914 0.919516  ]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 3]]\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "[[ 2  3]\n",
      " [ 6 11]]\n"
     ]
    }
   ],
   "source": [
    "print(\"NumPy:\")\n",
    "print(np.zeros((2, 2)))\n",
    "print(np.ones((2, 2)))\n",
    "print(np.full((2, 2), 5))\n",
    "print(np.arange(1, 9, 2).reshape(2, 2))\n",
    "print(np.random.normal(size=(2, 2)))\n",
    "print(np.random.uniform(size=(2, 2)))\n",
    "\n",
    "print(np.eye(2))\n",
    "print(np.diag(np.arange(4)))\n",
    "print(np.ones((2, 3)).T)\n",
    "print(np.dot(np.arange(4).reshape(2, 2), np.arange(4).reshape(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[5 5]\n",
      " [5 5]]\n",
      "[[1 3]\n",
      " [5 7]]\n",
      "[[-3.0080996   0.02691678]\n",
      " [-0.4987872   1.1137937 ]]\n",
      "[[0.56783473 0.19176853]\n",
      " [0.4971304  0.00339484]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 3]]\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "[[ 2  3]\n",
      " [ 6 11]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\")\n",
    "zeros = tf.zeros((2, 2))\n",
    "ones = tf.ones((2, 2))\n",
    "fills = tf.fill((2, 2), 5)\n",
    "ranges = tf.reshape(tf.range(1, 9, 2), (2, 2))\n",
    "normals = tf.random_normal((2, 2))\n",
    "uniforms = tf.random_uniform((2, 2))\n",
    "eye = tf.eye(2)\n",
    "diag = tf.diag(tf.range(4))\n",
    "transpose = tf.matrix_transpose(tf.ones((2, 3)))\n",
    "x = tf.reshape(tf.range(4), (2, 2))\n",
    "multiply = tf.matmul(x, x)\n",
    "matrice = [eye, diag, transpose, multiply]\n",
    "initializations = [zeros, ones, fills, ranges, normals, uniforms, eye, diag, transpose, multiply]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in initializations:\n",
    "        print(sess.run(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 變數（Variable）\n",
    "\n",
    "程式設計中為了保持彈性，必須將值賦與給變數（Variables），讓使用者能夠動態地進行相同的計算來得到不同的結果，這在 TensorFlow 中是以 tf.Variable() 來完成。\n",
    "\n",
    "但宣告變數張量並不如 Python 或者先前宣告常數張量那麼單純，它需要兩個步驟：\n",
    "\n",
    "1. 宣告變數張量的初始值、類型與外觀\n",
    "2. 初始化變數張量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "var_py = 47\n",
    "print(\"Python:\")\n",
    "print(var_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable\n\t [[{{node _retval_Variable_0_0}} = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\miniconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\miniconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\miniconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[{{node _retval_Variable_0_0}} = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5ad302d06aad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TensorFlow:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\miniconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\miniconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\miniconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\miniconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[0;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[{{node _retval_Variable_0_0}} = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]"
     ]
    }
   ],
   "source": [
    "# TensorFlow: FailedPreconditionError\n",
    "var_tf = tf.Variable(47)\n",
    "print(\"TensorFlow:\")\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(var_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "var_tf = tf.Variable(47)\n",
    "print(\"TensorFlow:\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_tf.initializer)\n",
    "    print(sess.run(var_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化成功後的變數張量，可以透過 .assign() 方法重新賦予不同值。\n",
    "\n",
    "重新賦値這件事對 TensorFlow 來說也是一個運算，必須在宣告之後放入 Session 中執行，否則重新賦值並不會有作用。\n",
    "\n",
    "重新賦值時必須要注意類型，賦予不同類型的值會得到 TypeError。\n",
    "\n",
    "不僅是值的類型，外觀也必須跟當初所宣告的相同，賦予不同外觀的值會得到 ValueError。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\n",
      "Before assign 47\n",
      "After assign 47\n"
     ]
    }
   ],
   "source": [
    "var_tf = tf.Variable(47)\n",
    "assign_op = var_tf.assign(24)\n",
    "\n",
    "print(\"TensorFlow:\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_tf.initializer)\n",
    "    print('Before assign',sess.run(var_tf))\n",
    "    #sess.run(assign_op)\n",
    "    print('After assign',sess.run(var_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:\n",
      "Before assign [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "After assign [[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "var_tf = tf.Variable(np.ones([3, 4]))\n",
    "#assign_op = var_tf.assign(24)\n",
    "assign_op = var_tf.assign(np.arange(12).reshape(3, 4))\n",
    "\n",
    "print(\"TensorFlow:\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_tf.initializer)\n",
    "    print('Before assign',sess.run(var_tf))\n",
    "    sess.run(assign_op)\n",
    "    print('After assign',sess.run(var_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 佔位符(Placeholder)\n",
    "\n",
    "在Tensorflow中我們都是先建好Graph再決定資料的input與output，在上面的例子由於我們已經先定義好constant Tensor所以並不需要給Graph任何Input我們就可以得到各種張量運算的output，但如果我們操作的不是常數張量呢?\n",
    "\n",
    "這時候我們就需要Placeholder來幫助我們在還沒有資料的時候先佔個位子，這是一種常見將資料輸入 TensorFlow 計算圖形（Graph）的方法。\n",
    "\n",
    "Placeholder 張量和變數張量一樣，必須預先定義好之後欲輸入的資料類型與外觀。使用 tf.placeholder() 可以建出 Placeholder 張量。\n",
    "\n",
    "宣告完 Placeholder 以後，TensorFlow 資料輸入placeholder的術語稱作是 Feed dictionaries，顧名思義就是將資料以 Python dictionaries 餵進（Feed）Placeholder 張量之中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(4,), dtype=float32) Tensor(\"Placeholder_1:0\", shape=(4,), dtype=float32)\n",
      "Tensor(\"add_4:0\", shape=(4,), dtype=float32)\n",
      "[12. 24. 36. 48.]\n"
     ]
    }
   ],
   "source": [
    "p1 = tf.placeholder(tf.float32, shape=(4,))\n",
    "p2 = tf.placeholder(tf.float32, shape=(4,))\n",
    "\n",
    "print(p1,p2)\n",
    "add_op = p1 + p2\n",
    "print(add_op)\n",
    "with tf.Session() as sess:\n",
    "    adder=sess.run(add_op, feed_dict={p1: [7, 14, 21, 28], p2: [5, 10, 15, 20]})\n",
    "    print(adder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
